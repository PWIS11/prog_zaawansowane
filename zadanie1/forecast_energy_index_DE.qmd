---
title: "Prognozowanie Syntetycznego Wskaźnika Rozwoju Sektora Energetycznego w Niemczech"
author: "Izabela Reszka, Klaudia Woźniak, Piotr Wiśniewski"
date: "today"
format:
  pdf:
    toc: true                # Generuje spis treści
    toc-title: "Spis treści" # Tytuł spisu treści
    number-sections: true    # Numeruje rozdziały (np. 1. Wstęp)
    lang: pl                 # Ustawia polskie kodowanie dla LaTeX
---

# 1. Wstęp

Transformacja energetyczna, w Niemczech znana jako *Energiewende*, jest jednym z najbardziej złożonych procesów gospodarczych XXI wieku. Polega ona na fundamentalnej przebudowie sektora – odchodzeniu od paliw kopalnych i energetyki jądrowej na rzecz odnawialnych źródeł energii (OZE). Proces ten jest wielowymiarowy i nie da się go opisać za pomocą jednej zmiennej, takiej jak sama produkcja energii z wiatru czy cena giełdowa. Inwestorzy, analitycy oraz decydenci polityczni potrzebują zagregowanego, syntetycznego miernika, który – na wzór Produktu Krajowego Brutto dla gospodarki – pozwoli w jednej liczbie uchwycić ogólną kondycję i postęp tej transformacji.

Celem niniejszego projektu jest zaprojektowanie, zbudowanie i prognozowanie takiego syntetycznego wskaźnika rozwoju dla niemieckiego sektora energetycznego. Analiza opiera się na publicznie dostępnych danych z europejskiej platformy ENTSO-E oraz niemieckiej platformy SMARD.

Główne cele badawcze projektu są następujące:

1.  Wybór i uzasadnienie kluczowych zmiennych diagnostycznych opisujących niemiecki rynek energii (m.in. udział OZE, ceny rynkowe, stabilność systemu).
2.  Budowa trzech wariantów syntetycznego wskaźnika przy użyciu metod ważenia: równej wagi (EW), analizy składowych głównych (PCA) oraz metody wag entropowych (EWM).
3.  Zaprojektowanie i testowanie dwóch fundamentalnie różnych podejść do prognozowania wskaźnika na okres dwóch lat.
4.  Porównanie skuteczności obu strategii prognostycznych przy użyciu miar błędu ex-post, w tym RMSPE i współczynnika Theila.

Praca przedstawia metodykę pozyskania i agregacji danych, konstrukcję wskaźników oraz szczegółową analizę porównawczą wyników prognoz, kończąc na wnioskach dla sektora.

# 2. Źródła danych i Metodyka Badawcza

Badanie opiera się na danych wtórnych pozyskanych z oficjalnych platform monitorujących europejski rynek energii. Proces badawczy obejmował ekstrakcję danych surowych, ich transformację (ETL), konstrukcję zmiennych diagnostycznych oraz budowę modeli prognostycznych.

## 2.1. Charakterystyka źródeł danych

Głównym źródłem danych jest **ENTSO-E Transparency Platform** (European Network of Transmission System Operators for Electricity). Jest to centralne repozytorium danych dla europejskiego rynku energii elektrycznej, funkcjonujące na mocy Rozporządzenia Komisji (UE) nr 543/2013. Platforma zapewnia dostęp do danych o generacji, obciążeniu i cenach w wysokiej rozdzielczości czasowej (15-60 minut).

Jako źródło uzupełniające i weryfikacyjne wykorzystano platformę **SMARD**, prowadzoną przez niemieckiego regulatora (Bundesnetzagentur). SMARD agreguje dane z ENTSO-E, zapewniając ich walidację i przejrzystą strukturę dla rynku niemieckiego.

Zakres czasowy badania obejmuje okres od **stycznia 2015 r.** (początek pełnego raportowania ENTSO-E) do **października 2025 r.**, co daje łącznie 130 obserwacji miesięcznych.

## 2.2. Zmienne diagnostyczne

Na podstawie literatury przedmiotu wyselekcjonowano zestaw 6 zmiennych diagnostycznych, opisujących kluczowe wymiary rozwoju sektora:

1.  **Udział OZE (`res_share`):** Stosunek generacji ze źródeł odnawialnych (wiatr, słońce, woda, biomasa) do generacji całkowitej. Jest to stymulanta (wzrost oznacza postęp transformacji).
2.  **Udział paliw kopalnych (`fossil_share`):** Stosunek generacji z węgla, gazu i ropy do generacji całkowitej.Jest to destymulanta (pożądany jest spadek).
3.  **Cena rynkowa (`market_price`):** Średnia cena hurtowa energii elektrycznej na rynku dnia następnego (Day-Ahead Market) wyrażona w EUR/MWh. Traktowana jako destymulanta (wzrost ceny obniża konkurencyjność gospodarki).
4.  **Zmienność cen (`price_volatility`):** Odchylenie standardowe cen godzinowych w danym miesiącu. Mierzy ryzyko rynkowe i niepewność (destymulanta).
5.  **Całkowite zużycie (`energy_consumption`):** Sumaryczny wolumen energii zużytej w gospodarce (MWh). Wskaźnik skali rynku (stymulanta).
6.  **Stabilność systemu (`system_stability`):** Mierzona jako średni procentowy błąd prognozy zapotrzebowania operatora (MAPE). Niższy błąd oznacza wyższą stabilność i przewidywalność systemu (destymulanta).

## 2.3. Przygotowanie i agregacja danych (ETL)

Proces przygotowania danych został zrealizowany w środowisku Python przy użyciu biblioteki `entsoe-py`. Kluczowe etapy obejmowały:

* **Unifikacja stref cenowych:** Uwzględniono historyczny podział strefy cenowej DE-AT-LU (Niemcy-Austria-Luksemburg), który nastąpił 1 października 2018 r. Dane sprzed tej daty dla strefy połączonej zostały scalone z danymi dla strefy DE-LU (Niemcy-Luksemburg).
* **Agregacja czasowa:** Dane surowe o granularności 15-minutowej (obciążenie) i godzinowej (ceny) zostały zagregowane do częstotliwości miesięcznej (`ME`). Zastosowano sumowanie dla wolumenów (MWh) oraz średnią dla cen i wskaźników procentowych.
* **Flaga kryzysowa:** Utworzono binarną zmienną pomocniczą `crisis_flag`, przyjmującą wartość 1 dla okresów pandemii COVID-19 (03.2020–06.2021) oraz kryzysu energetycznego (09.2021–12.2023).

## 2.4. Metody konstrukcji wskaźnika syntetycznego

W celu zbudowania syntetycznego miernika rozwoju (SMR) zastosowano procedurę unitaryzacji zerowanej (standaryzacja Z-Score), sprowadzającą zmienne do porównywalności. Następnie obliczono trzy warianty wskaźnika:

1.  **Metoda Równych Wag (EW):** Średnia arytmetyczna ze wszystkich unormowanych zmiennych. Zakłada jednakowy wpływ każdego czynnika na rozwój sektora.
2.  **Analiza Składowych Głównych (PCA):** Metoda redukcji wymiaru, w której wagi wyznaczane są na podstawie ładunków pierwszej składowej głównej, wyjaśniającej największą część wariancji zbioru danych.
3.  **Metoda Wag Entropowych (EWM):** Podejście obiektywne, w którym wagi zależą od stopnia nieuporządkowania informacji (entropii). Zmienne o większej zmienności otrzymują wyższe wagi, jako niosące więcej unikalnej informacji.

## 2.5. Metodyka prognozowania

Badanie porównuje dwie strategie prognostyczne dla horyzontu 24 miesięcy:
* **Podejście bezpośrednie:** Prognozowanie finalnego indeksu syntetycznego.
* **Podejście pośrednie (agregacja):** Prognozowanie każdego składnika z osobna, a następnie ich scalenie w indeks.

W podejściu bezpośrednim do prognozowania syntetycznych wskaźników zastosowano zestaw modeli klasycznych, a następnie wybrano te, które zapewniały najniższe błędy ex‑post na zbiorze testowym (ostatnie 24 miesiące). Dla indeksu EW oraz PCA najlepsze dopasowanie uzyskano przy użyciu modelu **Holt‑Winters**, natomiast dla indeksu EWM – modelu **ETS**. Jakość prognoz oceniono przy użyciu pełnego zestawu miar trafności: **ME** (średni błąd), **MPE** (średni błąd procentowy), **MAE** (średni błąd bezwzględny), **MAPE** (średni błąd procentowy bezwzględny), **RMSE** (pierwiastek błędu średniokwadratowego), **RMSPE** (względny błąd średniokwadratowy) oraz **współczynnika Theila**.

# 3. Analiza i Wyniki

W niniejszym rozdziale przedstawiono wyniki analizy empirycznej. Proces badawczy podzielono na trzy etapy: wstępną eksplorację danych (EDA), konstrukcję wskaźników syntetycznych oraz modelowanie prognostyczne.

## 3.1. Wstępna analiza danych (EDA)

Pierwszym krokiem jest wczytanie przygotowanych danych miesięcznych oraz analiza ich podstawowych statystyk opisowych. Pozwala to na weryfikację poprawności danych oraz identyfikację ogólnych charakterystyk badanego okresu (2015–2025).

```{python}
#| label: wczytanie-i-statystyki
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "Statystyki opisowe zmiennych diagnostycznych (2015-2025)"

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

# Konfiguracja stylu
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_context("paper")

# --- WCZYTANIE DANYCH ---

filename = "dane_miesieczne_DE.csv"
folder = "dane_po_transformacji"
path_in_folder = os.path.join(folder, filename)

if os.path.exists(path_in_folder):
    file_path = path_in_folder
elif os.path.exists(filename):
    file_path = filename
else:
    raise FileNotFoundError(f"Nie znaleziono pliku {filename}")

df = pd.read_csv(file_path)
# Parsowanie daty (format pełny z CSV)
df['date_dt'] = pd.to_datetime(df['date'], utc=True)
df = df.set_index('date_dt')

diagnostic_vars = [
    'res_share', 'fossil_share', 'market_price', 
    'price_volatility', 'energy_consumption', 'system_stability'
]

# --- PRZYGOTOWANIE TABELI STATYSTYK ---
df_display = df[diagnostic_vars].copy()

# Konwersja Energy Consumption z MWh na TWh
df_display['energy_consumption'] = df_display['energy_consumption'] / 1_000_000

# Obliczanie statystyk
stats = df_display.describe().T
stats = stats[['mean', 'std', 'min', '50%', 'max']]

# Dodanie Współczynnika Zmienności (Coefficient of Variation) w %
stats['CV (%)'] = (stats['std'] / stats['mean']) * 100

# Zmiana nazw kolumn na polskie
stats.columns = ['Średnia', 'Odchylenie Std.', 'Min', 'Mediana', 'Max', 'Zmienność (CV %)']

# Mapowanie nazw zmiennych
variable_names = {
    'res_share': 'Udział OZE (ułamek)',
    'fossil_share': 'Udział Paliw Kopalnych (ułamek)',
    'market_price': 'Cena Rynkowa [EUR/MWh]',
    'price_volatility': 'Zmienność Cen (wew. miesiąca)',
    'energy_consumption': 'Zużycie Energii [TWh]',
    'system_stability': 'Błąd Prognozy MAPE (Stabilność)'
}
stats = stats.rename(index=variable_names)

# Wyświetlenie tabeli
print(stats.to_markdown(floatfmt=".4f"))
```

## 3.1.1. Wizualizacja szeregów czasowych

Wizualizacja przebiegu zmiennych w czasie pozwala zidentyfikować trendy, sezonowość oraz wpływ szoków zewnętrznych. Na wykresach poniżej zacieniowano okresy kryzysowe:

Szary obszar: Pandemia COVID-19 (03.2020 – 06.2021).

Czerwony obszar: Kryzys energetyczny i wojna w Ukrainie (09.2021 – 12.2023).

```{python}
#| label: wizualizacja-szeregow
#| echo: false
#| fig-cap: "Przebieg zmiennych diagnostycznych w latach 2015-2025."
#| fig-height: 10
#| warning: false

fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10))
axes = axes.flatten()

# Słownik tytułów dla lepszej czytelności
titles = {
    'res_share': 'Udział OZE (Stymulanta)',
    'fossil_share': 'Udział Paliw Kopalnych (Destymulanta)',
    'market_price': 'Cena Rynkowa [EUR/MWh]',
    'price_volatility': 'Zmienność Cen',
    'energy_consumption': 'Zużycie Energii [MWh]',
    'system_stability': 'Błąd Prognozy (Stabilność)'
}

colors = ['green', 'black', 'blue', 'purple', 'orange', 'brown']

for i, col in enumerate(diagnostic_vars):
    ax = axes[i]
    ax.plot(df.index, df[col], color=colors[i], linewidth=1.5)
    ax.set_title(titles.get(col, col), fontsize=10, fontweight='bold')
    
    # Oznaczenie kryzysów
    ax.axvspan('2020-03-01', '2021-06-30', color='gray', alpha=0.15, label='COVID-19')
    ax.axvspan('2021-09-01', '2023-12-31', color='red', alpha=0.10, label='Kryzys Energetyczny')
    
    ax.grid(True, alpha=0.3)
    
    # Legenda tylko dla pierwszego wykresu
    if i == 0:
        ax.legend(loc='upper left', fontsize=8)

plt.tight_layout()
plt.show()
```

Analiza wizualna szeregów czasowych pozwala na sformułowanie trzech kluczowych wniosków dotyczących dynamiki niemieckiego rynku energii w badanym okresie:

Strukturalna transformacja miksu energetycznego: Zmienne Udział OZE oraz Udział Paliw Kopalnych wykazują wyraźny, długoterminowy trend deterministyczny. Obserwujemy systematyczny wzrost znaczenia źródeł odnawialnych przy jednoczesnym spadku generacji konwencjonalnej. Zjawisko to potwierdza postępującą realizację celów Energiewende, choć widoczna jest silna sezonowość wynikająca z warunków pogodowych (wietrzność i nasłonecznienie).

Wpływ szoków egzogenicznych na ceny: Przebieg zmiennej Cena Rynkowa oraz Zmienność Cen wskazuje na wystąpienie ekstremalnej anomalii w latach 2021–2022 (obszar zacieniowany na czerwono). Wzrost cen do poziomów przekraczających 400 EUR/MWh nie wynikał z cykli koniunkturalnych, lecz był skutkiem szoku podażowego (kryzys gazowy i wojna w Ukrainie). Wcześniejszy okres pandemii COVID-19 (obszar szary) charakteryzował się z kolei presją deflacyjną na ceny energii.

Stabilność popytu a zmienność rynku: Zmienna Zużycie Energii wykazuje wysoką stabilność i silną sezonowość roczną, z jedynie niewielkim załamaniem w pierwszej fazie pandemii. Kontrastuje to z gigantyczną zmiennością strony cenowej. Oznacza to, że rynek energii w Niemczech jest sztywny popytowo – drastyczne zmiany cen w niewielkim stopniu przekładają się na natychmiastową redukcję konsumpcji.

## 3.1.2. Mapa ciepła korelacji (Iza)
Opis: W tej sekcji należy przedstawić macierz korelacji Pearsona dla zmiennych diagnostycznych. Celem jest identyfikacja siły i kierunku powiązań między zmiennymi (np. czy wzrost udziału OZE faktycznie wiąże się ze spadkiem emisji paliw kopalnych). Jest to kluczowy krok uzasadniający użycie metody PCA, która redukuje wymiarowość silnie skorelowanych danych. Należy również zweryfikować, czy zmienne nie są ze sobą tożsame (korelacja bliska 1 lub -1).


```{python}
# --HEATMAPA--

import seaborn as sns
df_heatmapa = df[diagnostic_vars]
plt.figure(figsize=(8,6))
corr = df_heatmapa.corr()  
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Heatmapa korelacji zmiennych")
plt.show()

```


Najbardziej fundamentalną zależnością, widoczną na pierwszy rzut oka, jest niemal idealna ujemna korelacja ($r = -0.96$) pomiędzy udziałem źródeł odnawialnych (**res_share**) a udziałem paliw kopalnych (**fossil_share**). Oznacza to, że wzrost generacji z OZE niemal automatycznie i proporcjonalnie skutkuje redukcją produkcji z elektrowni konwencjonalnych. Jest to dowód na bezpośrednie wypieranie energetyki konwencjonalnej przez źródła odnawialne.

Drugim istotnym wnioskiem jest bardzo silna korelacja dodatnia ($r = 0.93$) łącząca cenę rynkową (**market_price**) z jej zmiennością (**price_volatility**). Oznacza to, że okresy drogiej energii nie są stabilne – wysokim cenom towarzyszą gwałtowne wahania (skoki cenowe). Wskazuje to, że szoki cenowe (np. kryzys energetyczny 2021-2022) destabilizują rynek, czyniąc go nieprzewidywalnym dla uczestników.

Interesujące zależności ujawnia również analiza całkowitego zużycia energii (**energy_consumption**). Zmienna ta jest dodatnio skorelowana z udziałem paliw kopalnych ($0.60$) i ujemnie z udziałem OZE ($-0.62$). Wynika to z charakterystyki sezonowej: najwyższe zapotrzebowanie na energię w Niemczech występuje zimą, kiedy generacja słoneczna (kluczowy składnik OZE) jest minimalna, a system musi być bilansowany przez sterowalne elektrownie węglowe i gazowe.

Ciekawym spostrzeżeniem jest brak istotnej korelacji liniowej pomiędzy ceną energii (**market_price**) a strukturą produkcji ($fossil_share: -0.02$, $res_share: 0.15$). Wskazuje to, że ceny hurtowe w badanym okresie były determinowane głównie przez czynniki zewnętrzne i geopolityczne (np. globalne ceny surowców), a nie przez lokalny udział wiatru czy węgla w systemie. Potwierdza to słuszność uwzględnienia ceny jako osobnej, niezależnej zmiennej diagnostycznej, gdyż niesie ona zupełnie inne informacje niż dane o produkcji



## 3.2. Konstrukcja i analiza wskaźników syntetycznych (Iza)
Opis: Sekcja ta opisuje proces transformacji surowych zmiennych w gotowe indeksy. Należy przeprowadzić standaryzację zmiennych (Z-Score) w celu doprowadzenia ich do porównywalności. Następnie, na bazie ujednoliconych danych, należy obliczyć trzy warianty wskaźnika:

```{python}
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA
# --Stymulanty + Destymulanty--

# kopia żeby nie psuć oryginału

X = df[diagnostic_vars].copy()

# Destymulanty
# - fossil_share (chcemy mniej)
# - market_price (dla konsumenta niższa cena = lepiej)
# - price_volatility (stabilność = lepiej)
# - system_stability (mniejszy błąd = lepiej)
destymulanty = ['fossil_share', 'market_price', 'price_volatility', 'system_stability']

# zamiana destymulant na stymulanty przez mnożenie * -1
for col in destymulanty:
    X[col] = -X[col]


# --STANDARYZACJA--

scaler_std = StandardScaler()
X_std = pd.DataFrame(scaler_std.fit_transform(X), columns=X.columns, index=X.index)
print('\nPrzykładowe wiersze po standaryzacji:')
print(X_std.head())


```

## EW (Equal Weighting): Prosta średnia arytmetyczna.

```{python}
idx_ew = X_std.mean(axis=1)
print(idx_ew)
```

## PCA (Principal Component Analysis): Wyznaczenie pierwszej składowej głównej, która wyjaśnia największą część wariancji.

```{python}
pca = PCA(n_components=1)
pca_values = pca.fit_transform(X_std).flatten()
idx_pca = pd.Series(pca_values, index=X.index)



weights_pca = pd.Series(pca.components_[0], index=X_std.columns)
print("Wagi PCA dla zmiennych:")
print(weights_pca)


```

## EWM (Entropy Weighting Method): Wyliczenie wag na podstawie entropii Shannona (im większa zmienność danych, tym większa waga). Wynikiem ma być wykres liniowy porównujący przebieg tych trzech indeksów w czasie.

```{python}
scaler_minmax = MinMaxScaler()
X_norm = pd.DataFrame(scaler_minmax.fit_transform(X), columns=X.columns, index=X.index)

epsilon = 1e-8
P = X_norm / (X_norm.sum(axis=0) + epsilon)
P = np.where(P == 0, epsilon, P) 

k = 1 / np.log(len(X_norm))
E = -k * (P * np.log(P)).sum(axis=0)
d = 1 - E


# Obliczenie wag
weights_ewm = d / d.sum()

idx_ewm = (X_norm * weights_ewm).sum(axis=1)
print("\nWagi EWM:", {col: round(w, 4) for col, w in zip(diagnostic_vars, weights_ewm)})

```

## Porównanie wskaźników

```{python}

results = pd.DataFrame({
    'EW (Średnia)': idx_ew,
    'PCA (Główna Składowa)': idx_pca,
    'EWM (Entropia)': idx_ewm
}, index=X.index)

# skalowanie osi, bez przeskalowania EWM było bardzo płaskie
results_scaled = pd.DataFrame(
    scaler_minmax.fit_transform(results), 
    columns=results.columns, 
    index=results.index
)

plt.figure(figsize=(12, 6))
plt.plot(results_scaled.index, results_scaled['EW (Średnia)'], label='EW', color='blue', alpha=0.6, linestyle='--')
plt.plot(results_scaled.index, results_scaled['PCA (Główna Składowa)'], label='PCA', color='green', alpha=0.6, linestyle='--')
plt.plot(results_scaled.index, results_scaled['EWM (Entropia)'], label='EWM', color='red', linewidth=2)

plt.title('Porównanie Znormalizowanych Indeksów (Skala 0-1)')
plt.ylabel('Wartość Indeksu')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()
```


Wykres przedstawia trzy indeksy (EW, PCA i EWM), które poruszają się w podobnych cyklach, ale różnią się wrażliwością na zmiany. EW jest najbardziej stabilny, utrzymuje się zwykle w przedziale 0.4–0.8 i dobrze oddaje średni poziom analizowanego zjawiska.

PCA cechuje się najwyższą zmiennością. Ponieważ wagi są wyznaczane na podstawie wariancji i struktury korelacji między zmiennymi, wskaźnik ten silnie reaguje na skoki w danych – zwłaszcza w okresach zakłóceń rynkowych. Największe wahania PCA obserwujemy w latach 2015, 2021 oraz 2025, kiedy pojawiały się strukturalne zmiany w miksie energetycznym lub szoki cenowe. PCA odzwierciedla zatem zmienność systemową, a nie tylko poziom rozwoju. 

EWM pozostaje między nimi: jest wygładzony, ale nadal wyraźnie reaguje na krótkookresowe zmiany, co widać np. w silnym spadku w 2022 roku i stabilnym wzroście po 2023 roku. Największe różnice między indeksami pojawiają się w okresach podwyższonej zmienności (2021–2022 oraz 2024–2025), kiedy PCA sygnalizuje silne skoki, podczas gdy EW pozostaje stabilny, a EWM reaguje szybciej, lecz z pewnym opóźnieniem. Wspólnie serie pokazują, że mimo tej samej ogólnej dynamiki, każdy indeks uchwyca inną stronę zjawiska: EW – średni trend, EWM – bieżący moment i punkty zwrotne, a PCA – strukturalną zmienność danych.



## 3.3. Podejście 1: Prognoza bezpośrednia indeksu (Klaudia)

W tym podejściu traktujemy obliczone wcześniej indeksy syntetyczne (EW, PCA, EWM) jako gotowe szeregi czasowe. Celem jest dopasowanie do nich najlepszego modelu prognostycznego (np. SARIMA lub Holt-Winters) i wygenerowanie prognozy na 24 miesiące do przodu. Należy podzielić zbiór na treningowy i testowy (ostatnie 2 lata), aby sprawdzić jakość modelu.

```{python}

#| label: podział-na-zbiory
#| echo: true
#| fig-cap: "Podział na zbiory: testowy i treningowy"
#| warning: false

freq = 'M'  
steps_ahead = 24  
train = idx_ew.iloc[:-steps_ahead]
test = idx_ew.iloc[-steps_ahead:]

print(f'Liczba obserwacji w zbiorze treningowym: {len(train)}')
print(f'Liczba obserwacji w zbiorze testowym: {len(test)}')

```

Przy 130 obserwacjach miesięcznych modele mają wystarczająco dużo danych, aby uchwycić zarówno trend, jak i sezonowość. Podział na 106 miesięcy treningowych i 24 miesiące testowych pozwala rzetelnie ocenić jakość prognozy.

```{python}

#| label: funkcje-prognoz-bezposrednich-indeksów
#| echo: true
#| warning: false

from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Ocena jakości prognozy 
def eval_metrics(actual, pred):
    me = np.mean(pred - actual)
    mpe = 100*np.mean((pred - actual) / actual)
    mae = np.mean(np.abs(pred - actual))
    mape = 100*np.mean(np.abs((pred - actual) / actual))
    rmse = np.sqrt(np.mean((pred - actual) ** 2))
    rmspe = 100 * (rmse / np.mean(actual)) if np.mean(actual) != 0 else np.nan
    t = np.sqrt(np.mean(((pred[1:] - actual[1:])**2)) / np.mean((actual[1:]**2)))
    return {'ME': me, 'MPE': mpe, 'MAE': mae, 'MAPE': mape, 'RMSE': rmse, 'RMSPE': rmspe, 'Theil': t}

# Wybór najlepszego modelu 
def best_time_model(series, horizon, freq='M'):
    s = series.dropna()
    if freq == 'M':
        s = s.asfreq('ME')
    elif freq == 'Q':
        s = s.asfreq('Q')
    min_rmspe = np.inf
    best_pred = None
    best_str = ''

   
    # 1. OLS trend+sezon
    try:
        X = np.arange(len(s))
        dummies = pd.get_dummies(s.index.month, prefix='M') if freq == 'M' else None
        X_mat = np.column_stack([X, dummies.values]) if dummies is not None else X[:,None]
        model = sm.OLS(s.values, sm.add_constant(X_mat)).fit()
        exog_pred = np.column_stack([np.arange(len(s), len(s)+horizon),
                                     np.eye(dummies.shape[1])[[i%dummies.shape[1] for i in range(len(s), len(s)+horizon)]]]) if dummies is not None else np.arange(len(s), len(s)+horizon)[:,None]
        ols_pred = model.predict(sm.add_constant(exog_pred))
        rmspe_ols = 100*np.sqrt(np.mean(((model.fittedvalues - s.values)/s.values)**2))
        if rmspe_ols < min_rmspe:
            best_pred, best_str, min_rmspe = ols_pred, 'OLS trend+sezon', rmspe_ols
    except:
        pass

    # 2. Holt-Winters
    try:
        hw = ExponentialSmoothing(s, trend='add', seasonal='add', seasonal_periods=12).fit()
        hw_pred = hw.forecast(horizon)
        rmspe_hw = 100*np.sqrt(np.mean(((hw.fittedvalues - s.values)/s.values)**2))
        if rmspe_hw < min_rmspe:
            best_pred, best_str, min_rmspe = hw_pred, 'Holt-Winters', rmspe_hw
    except:
        pass

    # 3. SARIMA
    try:
        sarima = SARIMAX(s, order=(1,1,1), seasonal_order=(1,1,1,12)).fit(disp=False)
        sarima_pred = sarima.forecast(horizon)
        rmspe_sarima = 100*np.sqrt(np.mean(((sarima.fittedvalues - s.values)/s.values)**2))
        if rmspe_sarima < min_rmspe:
            best_pred, best_str, min_rmspe = sarima_pred, 'SARIMA', rmspe_sarima
    except:
        pass

    # 4. ETS
    try:
        ets = ExponentialSmoothing(s, trend='add', seasonal='add', seasonal_periods=12, damped_trend=True).fit()
        ets_pred = ets.forecast(horizon)
        rmspe_ets = 100*np.sqrt(np.mean(((ets.fittedvalues - s.values)/s.values)**2))
        if rmspe_ets < min_rmspe:
            best_pred, best_str, min_rmspe = ets_pred, 'ETS', rmspe_ets
    except:
        pass

    # 5. Prophet
    try:
        df_prophet = pd.DataFrame({'ds': s.index, 'y': s.values})
        model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)
        model.fit(df_prophet)
        future = pd.DataFrame({'ds': pd.date_range(s.index[-1] + pd.offsets.MonthEnd(1), periods=horizon, freq='M')})
        prophet_pred = model.predict(future)['yhat'].values
        rmspe_prophet = 100*np.sqrt(np.mean(((model.predict(df_prophet)['yhat'] - s.values)/s.values)**2))
        if rmspe_prophet < min_rmspe:
            best_pred, best_str, min_rmspe = prophet_pred, 'Prophet', rmspe_prophet
    except:
        pass

    # Fallback
    if best_pred is None or np.isnan(best_pred).any():
        print(f"\nWARNING: All models failed or produced NaNs. Using fallback forecast.")
        fallback_value = s.iloc[-1] if not s.empty and not np.isnan(s.iloc[-1]) else s.mean() if not s.empty else 0
        best_pred = np.full(horizon, fallback_value)
        best_str = "Fallback (Last Value or Mean)"

    return best_pred, best_str

```


```{python}

#| label: prognoza-bezposrednia-indeksu-wyniki
#| echo: true
#| fig-cap: "Prognozy bezpośrednie indeksów syntetycznych na 24 miesiące."
#| warning: fals

# Prognozy bezpośrednie dla indeksów 
print('\n>>> Prognozy BEZPOŚREDNIE indeksów na 24 miesiące do przodu <<<')
steps_ahead = 24
method_labels = {'EW': idx_ew, 'PCA': idx_pca, 'EWM': idx_ewm}
direct_metrics = {}

for met, idx in method_labels.items():
    train, test = idx.iloc[:-steps_ahead], idx.iloc[-steps_ahead:]
    pred, model_name = best_time_model(train, steps_ahead)
    metrics = eval_metrics(test.values, pred)
    direct_metrics[met] = {'Model': model_name, **{k: round(v,4) for k,v in metrics.items()}}

    plt.figure(figsize=(11,4))
    plt.title(f'Prognoza bezpośrednia indeksu [{met}] ({model_name})')
    plt.plot(idx, label='obserwacje', lw=2)
    plt.plot(test.index, pred, 'r--', label='prognoza', lw=2)
    plt.legend(); plt.grid(alpha=0.3); plt.show()

#  Tabela wyników 
print('\n===============================')
print('PODSUMOWANIE MIAR TRAFNOŚCI PROGNOZ (OKRES TESTOWY - Prognoza bezpośrednia):')
direct_metrics_df = pd.DataFrame(direct_metrics).T
display(direct_metrics_df)

```


W podejściu bezpośrednim do prognozowania indeksów syntetycznych (EW, PCA, EWM) zastosowano kilka modeli prognostycznych: Holt‑Winters, ETS oraz SARIMA i Prophet. Wyniki pokazują, że skuteczność prognozowania zależy od charakteru danego indeksu:

**Indeks EW** (*Equal Weights*) Najlepszy okazał się model Holt‑Winters, który dobrze uchwycił sezonowość i trend. Jednak wartości błędów procentowych (**MAPE > 180%**) są bardzo wysokie. Wynika to z faktu, że indeks EW ma stosunkowo niskie wartości, więc nawet niewielkie odchylenia prognozy przekładają się na duże błędy względne. Model częściowo uchwycił trend wzrostowy po kryzysie, ale w okresach gwałtownych zmian prognoza była mniej trafna.

**Indeks PCA** (*Principal Component Analysis*) Tutaj również najlepszy był **Holt‑Winters**, ale błędy są jeszcze wyższe niż w przypadku EW. PCA jest najbardziej zmiennym indeksem, ponieważ syntetyzuje wiele wskaźników o różnej dynamice. Wysoki poziom MAPE (**~188%**) pokazuje, że prognozowanie PCA jest szczególnie trudne – model nie radzi sobie dobrze z dużą zmiennością i nagłymi odchyleniami. Choć trend został częściowo uchwycony, prognoza nie jest stabilna i wymaga ostrożnej interpretacji.

**Indeks EWM** (*Exponential Weighted Mean*) Najlepszy wynik uzyskał model ETS, który bardzo dobrze dopasował się do danych. Błędy są niskie (**MAPE ~10%, RMSE ~0.07**), co świadczy o wysokiej jakości prognozy. Indeks EWM jest bardziej stabilny i mniej podatny na szoki, dlatego ETS z tłumionym trendem okazał się idealnym wyborem. Model uchwycił zarówno trend wzrostowy po kryzysie, jak i sezonowość, co czyni prognozę wiarygodną.

## 3.4. Podejście 2: Prognoza składników i agregacja (Klaudia)

To podejście alternatywne ("od dołu do góry"). Zamiast prognozować gotowy indeks, prognozujemy każdą z 6 zmiennych diagnostycznych osobno (np. osobno prognozujemy cenę prądu, osobno udział OZE). Dopiero mając prognozy tych składników na przyszłość, składamy je w indeks syntetyczny, używając wag wyliczonych w sekcji 3.2.

``` {python}

#| label: prognoza-skladnikow
#| echo: true
#| fig-cap: "Prognozowanie składników diagnostycznych."
#| warning: false

components = ['market_price', 'energy_consumption', 'res_share',
              'system_stability', 'fossil_share', 'price_volatility']
steps_ahead = 24
component_forecasts = {}

# Prognozowanie 6 powyższych zmiennych diagnostycznych 
for var in components:
    train, test = df[var].iloc[:-steps_ahead], df[var].iloc[-steps_ahead:]
    pred, model_name = best_time_model(train, steps_ahead)
    component_forecasts[var] = pred
    print(f"{var}: najlepszy model -> {model_name}")

```
    


```{python}

#| label: dopasowanie-treningowe
#| echo: true
#| fig-cap: "Dopasowanie modeli do danych treningowych."
#| warning: false

# Wizualizacja dopasowania modeli do danych treningowych
for var in components:
    train = df[var].iloc[:-steps_ahead]
    pred, model_name = best_time_model(train, steps_ahead)

    fitted = None
    try:
        if model_name == 'OLS trend+sezon':
            X = np.arange(len(train))
            dummies = pd.get_dummies(train.index.month, prefix='M')
            X_mat = np.column_stack([X, dummies.values])
            model = sm.OLS(train.values, sm.add_constant(X_mat)).fit()
            fitted = pd.Series(model.fittedvalues, index=train.index)

        elif model_name == 'Holt-Winters':
            model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=12).fit()
            fitted = pd.Series(model.fittedvalues, index=train.index)

        elif model_name == 'SARIMA':
            model = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,12),
                            enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)
            fitted = pd.Series(model.fittedvalues, index=train.index)

        elif model_name == 'ETS':
            model = ExponentialSmoothing(train, trend='add', seasonal='add',
                                         seasonal_periods=12, damped_trend=True).fit()
            fitted = pd.Series(model.fittedvalues, index=train.index)

    except Exception as e:
        print(f"Nie udało się uzyskać dopasowania dla {var}: {e}")

    plt.figure(figsize=(9,3))
    plt.plot(train.index, train, label='rzeczywiste', lw=2)
    if fitted is not None:
        plt.plot(fitted.index, fitted, 'b--', label='dopasowanie (train)', lw=2)
    plt.title(f'{var} – dopasowanie modelu ({model_name})')
    plt.legend(); plt.grid(alpha=0.3)
    plt.show()

```


Dopasowanie modeli do danych historycznych dla poszczególnych składników indeksów syntetycznych okazało się trafne i stabilne. Modele wygładzające (**Holt-Winters**) dobrze odwzorowały sezonowość i trend w zmiennych takich jak **energy_consumption**, **res_share** czy **fossil_share**. Z kolei modele SARIMA skutecznie uchwyciły zmienność i fluktuacje w składnikach takich jak **market_price** i **price_volatility**, szczególnie w okresie *2021–2023*. Model ETS zastosowany dla **system_stability** zapewnił stabilne dopasowanie przy niskiej amplitudzie danych.

Zaobserwowana zgodność pomiędzy wartościami rzeczywistymi a dopasowanymi w okresie treningowym wskazuje na wysoką adekwatność zastosowanych modeli prognostycznych względem charakterystyki poszczególnych zmiennych diagnostycznych. Brak istotnych odchyleń systematycznych oraz skuteczne odwzorowanie trendów i sezonowości potwierdzają, że procedura modelowania została przeprowadzona w sposób metodycznie uzasadniony.

W konsekwencji, podejście składnikowe – polegające na indywidualnym prognozowaniu komponentów i ich późniejszej agregacji – można uznać za statystycznie uzasadnione i prognostycznie stabilne. Stanowi ono wiarygodną podstawę do dalszej rekonstrukcji indeksów syntetycznych, zarówno w kontekście analizy porównawczej, jak i zastosowań decyzyjnych. 

```{python}
#| label: agregacja-indeksów
#| echo: true
#| fig-cap: "Przygotowanie prognoz składników i rekonstrukcja indeksów syntetycznych"
#| warning: false

# DataFrame z prognozami składników
forecast_df = pd.DataFrame(component_forecasts, index=test.index)

# Standaryzacja prognoz (dla EW i PCA)
scaler_std = StandardScaler().fit(df[components].iloc[:-steps_ahead])
forecast_std = pd.DataFrame(scaler_std.transform(forecast_df),
                            columns=forecast_df.columns, index=forecast_df.index)

# Normalizacja prognoz (dla EWM)
scaler_minmax = MinMaxScaler().fit(df[components].iloc[:-steps_ahead])
forecast_norm = pd.DataFrame(scaler_minmax.transform(forecast_df),
                             columns=forecast_df.columns, index=forecast_df.index)

# Wagi
weights_ew = np.ones(len(components)) / len(components)
pca = PCA(n_components=1).fit(scaler_std.transform(df[components].iloc[:-steps_ahead]))
ewm_weights = np.array([0.2473,0.1956,0.0433,0.0889,0.3239,0.1009])  


# Składanie indeksów
idx_ew_forecast = forecast_std.dot(weights_ew)
idx_pca_forecast = pd.Series(pca.transform(forecast_std).flatten(), index=forecast_std.index)
idx_ewm_forecast = forecast_norm.dot(ewm_weights)

```

Podejście składnikowe („od dołu do góry”) polega na prognozowaniu każdej zmiennej diagnostycznej osobno, a następnie rekonstrukcji indeksów syntetycznych na podstawie wag wyliczonych w sekcji 3.2. Dzięki temu możliwe jest indywidualne dopasowanie modelu do charakterystyki każdej zmiennej – np. dla stabilnych składników (takich jak **energy_consumption** czy **fossil_share**) zastosowano modele wygładzające (**Holt-Winters**), natomiast dla bardziej zmiennych (np. **market_price**, **price_volatility**) lepiej sprawdziły się modele SARIMA.

Po uzyskaniu prognoz dla wszystkich składników, zostały one przekształcone zgodnie z metodologią konstrukcji indeksów: standaryzacja dla EW i PCA, normalizacja dla EWM, a następnie agregacja z użyciem odpowiednich wag. W efekcie otrzymano prognozy składnikowe dla indeksów syntetycznych, które zostały porównane z wartościami rzeczywistymi w okresie testowym (24 miesiące).


```{python}

#| label: prognoza-skladnikow-i-agregacja-wyniki
#| echo: true
#| fig-cap: "Prognoza składników i rekonstrukcja indeksów syntetycznych - wykresy."
#| warning: false


# Wykresy porównawcze
plt.figure(figsize=(11,4))
plt.plot(idx_ew[-steps_ahead:], label='EW - rzeczywisty', lw=2)
plt.plot(idx_ew_forecast.index, idx_ew_forecast, 'r--', label='EW - prognoza składnikowa', lw=2)
plt.legend(); plt.grid(alpha=0.3); plt.title('Indeks EW – podejście składnikowe'); plt.show()

plt.figure(figsize=(11,4))
plt.plot(idx_pca[-steps_ahead:], label='PCA - rzeczywisty', lw=2)
plt.plot(idx_pca_forecast.index, idx_pca_forecast, 'r--', label='PCA - prognoza składnikowa', lw=2)
plt.legend(); plt.grid(alpha=0.3); plt.title('Indeks PCA – podejście składnikowe'); plt.show()

plt.figure(figsize=(11,4))
plt.plot(idx_ewm[-steps_ahead:], label='EWM - rzeczywisty', lw=2)
plt.plot(idx_ewm_forecast.index, idx_ewm_forecast, 'r--', label='EWM - prognoza składnikowa', lw=2)
plt.legend(); plt.grid(alpha=0.3); plt.title('Indeks EWM – podejście składnikowe'); plt.show()

# Ocena jakości prognoz składnikowych
aggregated_metrics = {}
for met, idx_pred, idx_actual in zip(['EW','PCA','EWM'],
                                     [idx_ew_forecast, idx_pca_forecast, idx_ewm_forecast],
                                     [idx_ew[-steps_ahead:], idx_pca[-steps_ahead:], idx_ewm[-steps_ahead:]]):
    metrics = eval_metrics(idx_actual.values, idx_pred.values)
    aggregated_metrics[met] = {'Model':'Składnikowa', **{k: round(v,4) for k,v in metrics.items()}}
    print(f"\n{met} – podejście składnikowe: {metrics}")

# Tabela wyników
print('\n===============================')
print('PODSUMOWANIE MIAR TRAFNOŚCI PROGNOZ (OKRES TESTOWY - Prognoza składnikowa):')
aggregated_metrics_df = pd.DataFrame(aggregated_metrics).T
display(aggregated_metrics_df)

``` 

*Wyniki miar trafności wskazują, że:*

**Indeks EW** osiągnął bardzo wysokie błędy względne **(MAPE = 228%, RMSPE = 245%)**, a współczynnik Theila przekroczył wartość 1 **(Theil = 1.40)**, co oznacza, że prognoza była gorsza niż prognoza naiwna. Równe wagi nie zrównoważyły wpływu zmiennych o dużej zmienności, co pogorszyło trafność.

**Indeks PCA** charakteryzował się największymi błędami bezwzględnymi **(MAE = 1.21, RMSE = 1.38)**, co wynika z większej skali indeksu. Mimo to, współczynnik Theila był niższy niż dla EW **(Theil = 0.64)**, co wskazuje na lepsze dopasowanie. PCA lepiej oddało strukturę współzależności między składnikami, ale nie zredukowało błędów względnych.

**Indeks EWM** uzyskał najlepsze wyniki: najniższe błędy bezwzględne **(MAE = 0.33, RMSE = 0.34)**, najniższe błędy względne **(MAPE = 56.6%, RMSPE = 58.8%)** oraz najniższy współczynnik Theila **(Theil = 0.59)**. Wagi entropowe skutecznie zrównoważyły wpływ składników, nadając większe znaczenie zmiennym o wysokiej informacyjności i stabilności.

## 3.5. Analiza porównawcza i Wnioski (Wspólne)
Opis: Zestawienie wyników z punktu 3.3 i 3.4. Tabela porównująca błędy (np. RMSE) dla obu podejść. Wskazanie zwycięskiej metody dla każdego typu indeksu.

# [PLACEHOLDER: Skrypt Python generujący tabelę porównawczą błędów (Podejście 1 vs Podejście 2)]

Komentarz analityczny: (Podsumowanie: Która metoda wygrała? Zazwyczaj "Podejście 2" (agregacja) jest stabilniejsze, ale "Podejście 1" może być lepsze, jeśli zmienne są mocno skorelowane. Należy wydać werdykt).

Propozycja: Możemy stworzyć prostą tabelkę: Wiersze to EW, PCA, EWM. Kolumny to RMSE (Bezpośrednia) i RMSE (Pośrednia). Zaznaczyć pogrubieniem najmniejsze błędy.

## 4. Wnioski i Rekomendacje dla Branży (Wspólne)

#Wstępnie wg własnych przemyśleń, do ustalenia później co i jak podsumujemy

Synteza Transformacji:

Jak wyglądał trend wskaźnika w ostatnich 10 latach? Czy transformacja (Energiewende) przyspiesza, czy hamuje?

Czy kryzys energetyczny (2022) trwale zmienił trajektorię rynku, czy był tylko chwilowym zaburzeniem?

Prognoza na 2026-2027 (Co mówią nasze modele?):

Czy modele przewidują stabilizację cen?

Czy udział OZE będzie rósł liniowo czy wykładniczo?

Co to oznacza dla inwestorów? (np. "Spadająca zmienność cen sugeruje mniejsze ryzyko dla inwestycji długoterminowych, ale mniejszą opłacalność dla magazynów energii zarabiających na arbitrażu").

#Dodatkowo:

Jasno wskazać, który indeks (EW, PCA czy EWM) najlepiej oddaje rzeczywistość niemiecką i dlaczego warto go stosować w future (np. "EWM najlepiej reaguje na szoki cenowe").

# 5. Bibliografia

* ENTSO-E Transparency Platform. Central collection and publication of electricity generation, transportation and consumption data and information for the pan-European market. Dostępne pod adresem: https://transparency.entsoe.eu/.
* SMARD.de. Electricity market data platform of the Bundesnetzagentur. Dostępne pod adresem: https://www.smard.de/.
* Komisja Europejska. Rozporządzenie Komisji (UE) nr 543/2013 z dnia 14 czerwca 2013 r. w sprawie dostarczania i publikowania danych na rynkach energii elektrycznej.
* Bundesnetzagentur. Monitoringbericht 2024 (Raport monitorujący rynek energii).